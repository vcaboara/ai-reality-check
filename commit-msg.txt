[AI] fix: resolve Ollama port conflict in docker-compose

Changes:
- Commented out Ollama service in docker-compose.yml
- Updated OLLAMA_BASE_URL to use host.docker.internal:11434 by default
- Updated default model to qwen2.5-coder:7b
- Removed depends_on for Ollama service

Rationale:
- Most users run Ollama locally on port 11434
- Having Docker try to start another Ollama causes port conflicts
- host.docker.internal allows container to reach host services
- Users who want containerized Ollama can uncomment the service

Now works without port conflicts when Ollama is running locally.

---
AI-Generated-By: GitHub Copilot (Claude Sonnet 4.5)
